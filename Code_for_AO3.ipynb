{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4642e4bf-9baa-4e25-b308-41f64077a9c5",
   "metadata": {},
   "source": [
    "# Code for AO3 recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99b2e4e-36e3-4843-9b7c-9800e28eaf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your username:  Dipit12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          author_name                                               tags  \\\n",
      "0  HispanicBriton7691  [Graphic Depictions Of Violence, Underage, Eri...   \n",
      "1              psiten  [No Archive Warnings Apply, Doumeki Shizuka/Wa...   \n",
      "2      orphan_account  [No Archive Warnings Apply, Feng Lan | Prince/...   \n",
      "3      McPhoenixDavid  [No Archive Warnings Apply, Itadori Yuuji & Uz...   \n",
      "\n",
      "                                              genres  \n",
      "0  [陰の実力者になりたくて！ | The Eminence in Shadow - Aizaw...  \n",
      "1  [Tsubasa: Reservoir Chronicle, xxxHoLic, X/199...  \n",
      "2                          [1/2 Wangzi | 1/2 Prince]  \n",
      "3  [呪術廻戦 | Jujutsu Kaisen (Manga), 呪術廻戦 | Jujutsu...  \n",
      "\n",
      "Distances for tags:\n",
      "[0.0000000e+00 1.8396928e+00 1.9424820e+00 1.9896122e+00 3.4028235e+38]\n",
      "\n",
      "Top 5 tags:\n",
      "['pure', 'okawa', 'hiromi', 'meta', 'good']\n",
      "Top stories for tag 'pure':\n",
      "https://archiveofourown.org/works/57524758\n",
      "https://archiveofourown.org/works/57307273\n",
      "https://archiveofourown.org/works/56515708\n",
      "https://archiveofourown.org/works/56477683\n",
      "https://archiveofourown.org/works/56433304\n",
      "\n",
      "\n",
      "Top stories for tag 'okawa':\n",
      "https://archiveofourown.org/works/55377097\n",
      "https://archiveofourown.org/works/54442438\n",
      "https://archiveofourown.org/works/48447040\n",
      "https://archiveofourown.org/works/44716573\n",
      "https://archiveofourown.org/works/43872898\n",
      "\n",
      "\n",
      "Top stories for tag 'hiromi':\n",
      "https://archiveofourown.org/works/48564919\n",
      "https://archiveofourown.org/works/48193939\n",
      "https://archiveofourown.org/works/48088513\n",
      "https://archiveofourown.org/works/45467464\n",
      "https://archiveofourown.org/works/32541874\n",
      "\n",
      "\n",
      "Top stories for tag 'meta':\n",
      "https://archiveofourown.org/works/57519658\n",
      "https://archiveofourown.org/works/57517645\n",
      "https://archiveofourown.org/works/57516055\n",
      "https://archiveofourown.org/works/57515188\n",
      "https://archiveofourown.org/works/57500533\n",
      "\n",
      "\n",
      "Top stories for tag 'good':\n",
      "https://archiveofourown.org/works/57524149\n",
      "https://archiveofourown.org/works/57512407\n",
      "https://archiveofourown.org/works/57510841\n",
      "https://archiveofourown.org/works/57498358\n",
      "https://archiveofourown.org/works/57472897\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "username = input(\"Enter your username: \")\n",
    "url = f\"https://archiveofourown.org/users/{username}/bookmarks\"\n",
    "response = requests.get(url)\n",
    "data = response.content\n",
    "\n",
    "def extract_bookmark_data(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    bookmarks = []\n",
    "\n",
    "    for bookmark in soup.select('li.bookmark.blurb.group'):\n",
    "        # Extract the author's name\n",
    "        author = bookmark.select_one('div.header.module h4 a[rel=\"author\"]').text if bookmark.select_one(\n",
    "            'div.header.module h4 a[rel=\"author\"]') else 'Unknown'\n",
    "\n",
    "        # Extract tags and user-set tags\n",
    "        tags = [tag.text for tag in bookmark.select('.tags.commas li a.tag')]\n",
    "        user_set_tags = [tag.text for tag in bookmark.select('.meta.tags.commas li a.tag')]\n",
    "        all_tags = tags + user_set_tags\n",
    "\n",
    "        # Extract genres\n",
    "        genres = [genre.text for genre in bookmark.select('h5.fandoms.heading a.tag')]\n",
    "\n",
    "        bookmarks.append({\n",
    "            \"author_name\": author,\n",
    "            \"tags\": all_tags,\n",
    "            \"genres\": genres\n",
    "        })\n",
    "\n",
    "    return bookmarks\n",
    "\n",
    "# Get extracted bookmark data\n",
    "bookmark_data = extract_bookmark_data(data)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(bookmark_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return x if isinstance(x, list) else []\n",
    "\n",
    "df['author_combined'] = df['author_name']\n",
    "df['tags_combined'] = df['tags'].apply(lambda x: ' '.join(safe_eval(x)))\n",
    "df['genres_combined'] = df['genres'].apply(lambda x: ' '.join(safe_eval(x)))\n",
    "\n",
    "vectorizer_author = TfidfVectorizer(stop_words=None, token_pattern=r'\\b\\w+\\b')\n",
    "vectorizer_tags = TfidfVectorizer(stop_words=None, token_pattern=r'\\b\\w+\\b')\n",
    "vectorizer_genres = TfidfVectorizer(stop_words=None, token_pattern=r'\\b\\w+\\b')\n",
    "\n",
    "def safe_transform(vectorizer, text):\n",
    "    try:\n",
    "        return vectorizer.fit_transform(text)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error transforming text: {e}\")\n",
    "        print(\"Problematic text:\", text)\n",
    "        return None\n",
    "\n",
    "tfidf_author_matrix = safe_transform(vectorizer_author, df['author_combined'])\n",
    "tfidf_tags_matrix = safe_transform(vectorizer_tags, df['tags_combined'])\n",
    "tfidf_genres_matrix = safe_transform(vectorizer_genres, df['genres_combined'])\n",
    "\n",
    "if tfidf_author_matrix is None or tfidf_tags_matrix is None or tfidf_genres_matrix is None:\n",
    "    print(\"One or more transformations failed. Cannot proceed.\")\n",
    "else:\n",
    "    tfidf_author_array = tfidf_author_matrix.toarray()\n",
    "    tfidf_tags_array = tfidf_tags_matrix.toarray()\n",
    "    tfidf_genres_array = tfidf_genres_matrix.toarray()\n",
    "\n",
    "    combined_vectors = np.hstack([tfidf_author_array, tfidf_tags_array, tfidf_genres_array])\n",
    "\n",
    "    dimension_author = tfidf_author_array.shape[1]\n",
    "    dimension_tags = tfidf_tags_array.shape[1]\n",
    "    dimension_genres = tfidf_genres_array.shape[1]\n",
    "\n",
    "    index_author = faiss.IndexFlatL2(dimension_author)\n",
    "    index_tags = faiss.IndexFlatL2(dimension_tags)\n",
    "    index_genres = faiss.IndexFlatL2(dimension_genres)\n",
    "\n",
    "    index_author.add(tfidf_author_array.astype(np.float32))\n",
    "    index_tags.add(tfidf_tags_array.astype(np.float32))\n",
    "    index_genres.add(tfidf_genres_array.astype(np.float32))\n",
    "\n",
    "    query_tags_vector = tfidf_tags_array[0].reshape(1, -1).astype(np.float32)\n",
    "\n",
    "    k = 5\n",
    "\n",
    "    distances_tags, tags_indices = index_tags.search(query_tags_vector, k)\n",
    "\n",
    "    print(\"\\nDistances for tags:\")\n",
    "    print(distances_tags.flatten())\n",
    "\n",
    "    inverse_tags_vectors = vectorizer_tags.inverse_transform(tfidf_tags_array[tags_indices.flatten()])\n",
    "\n",
    "    similar_tags = [', '.join(tags) for tags in inverse_tags_vectors]\n",
    "\n",
    "    # Get the top 5 tags based on the distances\n",
    "    top_5_tags = []\n",
    "    for tags in inverse_tags_vectors:\n",
    "        top_5_tags.extend(tags)\n",
    "    top_5_tags = list(set(top_5_tags))[:5]  # Get unique tags and limit to top 5\n",
    "\n",
    "    print(\"\\nTop 5 tags:\")\n",
    "    print(top_5_tags)\n",
    "\n",
    "def get_top_stories(tag):\n",
    "    tag_query = tag.replace(\" \", \"%20\")\n",
    "    search_url = f\"https://archiveofourown.org/works/search?work_search%5Bquery%5D=&work_search%5Btitle%5D=&work_search%5Bcreators%5D=&work_search%5Brevised_at%5D=&work_search%5Bcomplete%5D=&work_search%5Bcrossover%5D=&work_search%5Bsingle_chapter%5D=0&work_search%5Bword_count%5D=&work_search%5Blanguage_id%5D=&work_search%5Bfandom_names%5D={tag_query}&work_search%5Brating_ids%5D=&work_search%5Bcharacter_names%5D=&work_search%5Brelationship_names%5D=&work_search%5Bfreeform_names%5D=&work_search%5Bhits%5D=&work_search%5Bkudos_count%5D=&work_search%5Bcomments_count%5D=&work_search%5Bbookmarks_count%5D=&work_search%5Bsort_column%5D=_score&work_search%5Bsort_direction%5D=desc&commit=Search\"\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract the top 5 stories' URLs\n",
    "    story_urls = []\n",
    "    for work in soup.select('li.work.blurb.group')[:5]:\n",
    "        story_url = \"https://archiveofourown.org\" + work.select_one('h4.heading a')['href']\n",
    "        story_urls.append(story_url)\n",
    "    \n",
    "    return story_urls\n",
    "\n",
    "# Create a dictionary to store the top stories for each top tag\n",
    "top_stories = {tag: get_top_stories(tag) for tag in top_5_tags}\n",
    "\n",
    "# Print the top stories for each tag\n",
    "for tag, stories in top_stories.items():\n",
    "    print(f\"Top stories for tag '{tag}':\")\n",
    "    for story in stories:\n",
    "        print(story)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a2fd9-850c-4838-ba44-08523ec896f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
